{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zv43wg-hjxFv"
   },
   "outputs": [],
   "source": [
    "#Importa as bibliotecas essenciais\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import tifffile\n",
    "import skimage as ski\n",
    "from skimage.filters import threshold_multiotsu\n",
    "import cv2\n",
    "from skimage import data, io\n",
    "from skimage import exposure # Módulo onde o CLAHE está"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZaOC3FikWwm",
    "outputId": "5c95cee2-a74e-4914-b932-1d2186377dc2"
   },
   "outputs": [],
   "source": [
    "file_path = '/home/ronald/Schistossoma/original_data/30dias'#original_data/120dias/'\n",
    "\n",
    "path_destiny = '/home/ronald/Schistossoma/processed_files_30dias'\n",
    "\n",
    "file_path2 = '/home/ronald/Schistossoma/original_data/60dias'#original_data/120dias/'\n",
    "\n",
    "path_destiny2 = '/home/ronald/Schistossoma/processed_files_60dias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qoLudnFpALgT"
   },
   "outputs": [],
   "source": [
    "def rescale(data, min_value, max_value):\n",
    "  try:\n",
    "    data_min, data_max = data.min(), data.max()\n",
    "    data_scaled = np.round((data - data_min) * (max_value - min_value) / (data_max - data_min) + min_value)\n",
    "    data_scaled[data_scaled > max_value] = max_value          #Garante que após o arredondamento nenhum valor seja superior ao valor máximo definido\n",
    "    return data_scaled.astype(np.uint16)\n",
    "  except Exception as e:\n",
    "    print('Ocorreu um erro inesperado: {}'.format(e))\n",
    "    return None\n",
    "\n",
    "def calculate_treshold_and_variance_between_classes(image):\n",
    "  '''Calcula o threshold que maximiza a variância entre classes (método de Otsu),\n",
    "     assim como a variância máxima, para duas classes somente'''\n",
    "  intensity, count = np.unique(image, return_counts=True)\n",
    "\n",
    "  n = len(intensity)\n",
    "\n",
    "  probability = count/count.sum()\n",
    "\n",
    "  cumulative_probability = probability.cumsum()\n",
    "\n",
    "  E_i = intensity * probability\n",
    "\n",
    "  partial_weighted_sum = E_i.cumsum()\n",
    "\n",
    "  global_mean = E_i.sum()\n",
    "\n",
    "  mean_C1 = np.zeros_like(intensity, dtype=float)\n",
    "\n",
    "  cumulative_probability_C1 = np.zeros_like(intensity, dtype=float)\n",
    "\n",
    "  mean_C0 = partial_weighted_sum/cumulative_probability\n",
    "\n",
    "  mean_C1[:-1] = (partial_weighted_sum[-1] - partial_weighted_sum[:-1]) / (1 - cumulative_probability[:-1])\n",
    "\n",
    "  cumulative_probability_C1[:-1] = 1 - cumulative_probability[:-1]\n",
    "\n",
    "  variance_between_classes = cumulative_probability*(global_mean - mean_C0)**2+cumulative_probability_C1*(global_mean-mean_C1)**2\n",
    "\n",
    "  indice_maior_valor = np.argmax(variance_between_classes)\n",
    "\n",
    "  return intensity[indice_maior_valor], variance_between_classes[indice_maior_valor]\n",
    "\n",
    "\n",
    "def find_best_parameters(image):\n",
    "  clip_limits_to_try = np.arange(0.01,0.21,0.01)\n",
    "  kernel_sizes_to_try = [(8,8),(12,12),(16,16),(20,20),(24,24),(28,28),(32,32)]\n",
    "  clip_limits_index, kernel_sizes_index = np.meshgrid(np.arange(len(clip_limits_to_try)), np.arange(len(kernel_sizes_to_try)))\n",
    "  clip_limits_index, kernel_sizes_index = clip_limits_index.flatten(), kernel_sizes_index.flatten()\n",
    "  clip_limits = clip_limits_to_try[clip_limits_index]\n",
    "  kernel_sizes = [kernel_sizes_to_try[i] for i in kernel_sizes_index]\n",
    "  results = [\n",
    "    calculate_treshold_and_variance_between_classes(\n",
    "        rescale(exposure.equalize_adapthist(image, clip_limit=clip_limits[i], kernel_size=kernel_sizes[i]), min(image.ravel()), max(image.ravel()))\n",
    "    )\n",
    "    for i in range(len(clip_limits))\n",
    "  ]\n",
    "  thresholds, variances = zip(*results)\n",
    "  return int(thresholds[np.argmax(variances)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yM3fzV6T-_RJ",
    "outputId": "06d7c41b-3d97-44bf-cee9-47e5433bdfd6"
   },
   "outputs": [],
   "source": [
    "def interest_class(figure, fator_multiplicativo):\n",
    "  blur = cv2.GaussianBlur(figure, (65,65), 0)\n",
    "  threshold=find_best_parameters(blur)\n",
    "  SHG_class = figure.copy()\n",
    "  for row in SHG_class:\n",
    "    for i in range(len(row)):\n",
    "      if row[i] < threshold:\n",
    "        row[i] = 11*fator_multiplicativo\n",
    "  return SHG_class\n",
    "\n",
    "\n",
    "\n",
    "def processar_imagens(diretorio_origem, diretorio_destino):\n",
    "  archives_names = [f for f in os.listdir(diretorio_origem)\n",
    "                     if os.path.isfile(os.path.join(diretorio_origem, f)) \n",
    "                     and f.lower().endswith('.tif')\n",
    "                     and 'shg' in f]                             #Arquivos \".tif\" no diretório\n",
    "  os.makedirs(diretorio_destino, exist_ok=True)\n",
    "  os.makedirs(diretorio_destino+'/SHG', exist_ok=True)\n",
    "  count = 1\n",
    "  for figure in archives_names:\n",
    "    print('{}/{}'.format(count,len(archives_names)))\n",
    "    fator_multiplicativo = int([a for a in ((figure.strip()).replace('.tif','')).split('-') if 'acc' in a.lower()][0].lower().replace('acc',''))\n",
    "    image = ski.io.imread(os.path.join(diretorio_origem, figure))\n",
    "    results = list()\n",
    "    for c in range(image.shape[2]):\n",
    "      SHG_class = interest_class(image[:, :, c], fator_multiplicativo)\n",
    "      results.append(SHG_class)\n",
    "      if c==1:\n",
    "        base_name = os.path.splitext(figure)[0]  # Nome do arquivo sem extensão\n",
    "        original_png = f\"{base_name}_layer{c}_original.png\"\n",
    "        processed_png = f\"{base_name}_layer{c}_processed.png\"\n",
    "        # Normaliza a camada original para 0–255 e converte para uint8\n",
    "        original_layer_scaled = ((image[:, :, c] / 4095) * 255).astype(np.uint8)\n",
    "        processed_layer_scaled = ((SHG_class / 4095) * 255).astype(np.uint8)\n",
    "        #Salva as imagens PNG\n",
    "        ski.io.imsave(os.path.join(diretorio_destino, original_png), original_layer_scaled)\n",
    "        ski.io.imsave(os.path.join(diretorio_destino, processed_png), processed_layer_scaled)\n",
    "    results_array = np.stack(results)\n",
    "    # Converter para shape (T=1, Z=3, C=1, Y=512, X=512)\n",
    "    stack_4d = results_array[:, np.newaxis, :, :]             # (Z, 1, Y, X)    #Adiciona eixo do canal ao stack\n",
    "    stack_5d = stack_4d[np.newaxis, ...]              # (1, Z, 1, Y, X)         #Adiciona eixo do tempo ao stack\n",
    "    # Salvar como multi-TIFF\n",
    "    repository_and_image_path = diretorio_destino+'/SHG/'+ figure\n",
    "\n",
    "    tifffile.imwrite(\n",
    "    repository_and_image_path,\n",
    "    stack_5d,\n",
    "    photometric='minisblack',  # escala de cinza (0=preto, 255=branco)\n",
    "    metadata={'axes': 'TZCYX'},  # convenção usada por tifffile\n",
    "    resolution=(72, 72),       # DPI (igual ao do arquivo que você enviou)\n",
    "    imagej=True                # Adiciona cabeçalhos compatíveis com ImageJ/Zeiss\n",
    "    )\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/68\n",
      "2/68\n",
      "3/68\n",
      "4/68\n",
      "5/68\n",
      "6/68\n",
      "7/68\n",
      "8/68\n",
      "9/68\n",
      "10/68\n",
      "11/68\n",
      "12/68\n",
      "13/68\n",
      "14/68\n",
      "15/68\n",
      "16/68\n",
      "17/68\n",
      "18/68\n"
     ]
    }
   ],
   "source": [
    "processar_imagens(file_path, path_destiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processar_imagens(file_path2, path_destiny2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path3 = '/home/ronald/Schistossoma/original_data/control'#original_data/120dias/'\n",
    "\n",
    "path_destiny3 = '/home/ronald/Schistossoma/processed_files_control'\n",
    "\n",
    "processar_imagens(file_path3, path_destiny3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
